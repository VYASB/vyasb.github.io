<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Understanding the 'Understanding Diffusion Models- A Unified Perspective' paper | Bharat Vyas</title> <meta name="author" content="Bharat Vyas"> <meta name="description" content="Notes on the paper, and introduction to diffusion models"> <meta name="keywords" content="academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/tree.png"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://vyasb.github.io/blog/2023/intro-diffusion-models/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Bharat¬†</span>Vyas</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blogs<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching</a> </li> <li class="nav-item "> <a class="nav-link" href="/resume/">Resume</a> </li> <li class="nav-item "> <a class="nav-link" href="/gallery/">Gallery</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Understanding the 'Understanding Diffusion Models- A Unified Perspective' paper</h1> <p class="post-meta">March 12, 2023</p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a> ¬† ¬∑ ¬† <a href="/blog/tag/diffusionmodel"> <i class="fas fa-hashtag fa-sm"></i> diffusionModel,</a> ¬† <a href="/blog/tag/generativemodel"> <i class="fas fa-hashtag fa-sm"></i> generativeModel</a> ¬† </p> </header> <article class="post-content"> <h3 id="understanding-diffusion-models-a-unified-perspective">Understanding Diffusion Models: A Unified Perspective</h3> <p>This is just me reading this paper and making some notes on the go. Let me know if someone wants to discuss the paper or find something intersting in my notes. Pardon my casual poor language skills throughout üòÑ</p> <blockquote> <p>I will try to go through some concepts in detail, while we also talk briefly through other relevant concepts. The text is purely my interpretation of the published work by Calvin Luo, and please dont use these notes to understand the paper. Rather think of this text as an exercise to check if you understood the concepts better than me or not üòâ</p> </blockquote> <ul> <li> <p>As I mentioned , these are just some notes. I‚Äôd suggest read the <a href="https://arxiv.org/abs/2208.11970" rel="external nofollow noopener" target="_blank">Paper</a> first.</p> </li> <li> <p>I wont go in detail of many concepts but sure you can.</p> </li> <li> <p>Please let me know if you find any error in my understanding of concepts. Always feel great to be wrong üò≠</p> </li> </ul> <h2 id="introduction-"><font size="6" color="blue">Introduction </font></h2> <p>The goal of generative model is to learn a true data distribution <code class="language-plaintext highlighter-rouge">p(x)</code> given some observed samples <code class="language-plaintext highlighter-rouge">x</code>. The learned model can:</p> <ul> <li>Generate new samples from approximate data</li> <li>Evaluate the likelihood of sampled data</li> </ul> <p>There are various directions for generative models as mentioned in text. Generative Adversarial Networks (GANs) learn to model sampling in an adversarial manner.</p> <blockquote> <p>Adversarial means two sides which oppose each other. GANs have generator and discriminator networks both of which are trained in adversarial manner. One network tries to generate new data and the other attempts to predict if the output is fake or real data.</p> </blockquote> <p><code class="language-plaintext highlighter-rouge">Likelihood-based</code> generative models are another class where the model assign high likelihood to the observed data samples. These include - <em>Autoregressive models</em>, <em>Normalizing flows</em>, and <em>Variational Autoencoders (VAEs)</em>.</p> <blockquote> <p>An autoregressive (AR) model is a type of statistical model used for analyzing and predicting time series data. It determine the probabilistic correlation between elements in a sequence, and use the knowledge derived to guess the next element in an unknown sequence. For example, during training, an autoregressive model processes several English language sentences and identifies that the word ‚Äúis‚Äù always follows the word ‚Äúit‚Äù It then generates a new sequence that has ‚Äúit is‚Äù together.</p> </blockquote> <blockquote> <p>Normalizing flows are like starting with a simple shape, such as a ball of clay, and transforming it into a complex shape by squeezing and stretching it multiple times. Each transformation is reversible, so we can always go back to the ball shape. This process helps us model and understand complex patterns in data by starting from something simple and making it more intricate step-by-step.</p> </blockquote> <p>Thereare other types of genrative modeling like <code class="language-plaintext highlighter-rouge">Energy based modeling</code>, where we energy function to learn the distribution. Related to this, <code class="language-plaintext highlighter-rouge">Score based modeling</code> learn the score of energy based model as a neural network. In this paper, the author is describing both likelihood-basedd and score-based interpretations - and lots of maths BTS!! ü§ì</p> <h2 id="background-"><font size="6" color="blue">Background </font></h2> <h5 id="latent-variable-vs-platos-allegory-of-cave"><strong>Latent Variable v/s Plato‚Äôs Allegory of Cave</strong></h5> <p>Now this is something very interesting and intuitive interpretation of latent variable. For many modalities, the <em>latent</em> variable <code class="language-plaintext highlighter-rouge">z</code> is an unseen random variable that is inferred from the observed data and is used to represent or generate the given data.</p> <h6 id="but-what-is-the-paltos-allegory-of-cave-and-how-is-it-related-to-latent-variable">But what is the Palto‚Äôs allegory of cave and how is it related to latent variable?</h6> <p>In the Allegory, a group of people are chained inside a cave their whole life and can only see 2D shadows in front of them whch are generated by 3D objects (most probably some creatures or animals) passed before a fire. Now, everything they observe is a projection of actual objects which they never saw and would never see in future. To such people, they observe things by some high-dimensional abstarct concepts like- how far the shadow goes, speed of movement, or so on, but quite different concepts than normal people for sure. Since, the cave people can never see (or fully comprehend) the hidden objects they can still reason or infer about the objects using their own concepts. This reminds me of a very interesting reddit thread which could be a total BS but I enjoyed reading it <a href="https://www.reddit.com/r/AskScienceDiscussion/comments/7gvlhp/why_does_life_only_exist_in_three_dimensions/" rel="external nofollow noopener" target="_blank">thread link here</a>.</p> <p>Now analogously, the objects we see in everyday life can also be generated as function of some high-level representations - e.g., some absract properties like color, size, shape etc. Its just that our high-level representations are w.r.t 3D interpretation and cave people have the same for 2D shadows they see.</p> <p>The allegory illustrates the idea of latent variables as potentially unobservable representations that determine observations - sounds cool. But, (of course there is a but here) the idea also illustrates to learn a representation of higher dimension. In generative modeling, we try to learn a lower dimensional latent representation than the higehr ones. Think of it as a form of compression, and at the same time we try to uncover semantically meaningful structure describing observations. Also, if we were to learn high-dimensional representation then we would need very strong priors and things would become more complicated over time.</p> <p>So, this was the end of some cool analogy described in the paper. Its always nice to read some mix of philosophy and science. Now its time for some maths üòà</p> <h5 id="evidence-lower-bound"><strong>Evidence Lower Bound</strong></h5> <p>We start with the latent variable \(z\) and data we observe with the joint distribution \(p(x, z)\)</p> <p>In the ‚ÄúLikelihood based‚Äù generative modeling, we want to maximize the \(p(x)\) of all observed $ x $. There are two ways we could manipulate the joitn distribution to recover the likelihood of purely observed data \(p(x)\).</p> <p>The first one is: we explicitly marginalize out the latent variable $ z $. The marginal distribution is obtained by integrating \(p(x, z)\) with respect to \(z\).</p> \[p(x) = \int p(x, z) \, dz\] <p>Here, out latent variable \(z\) is a continous varibale, and we want to sum over all the possible values of latent variable (becasue \(x\) can occur with any value of \(z\))</p> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> ¬© Copyright 2025 Bharat Vyas. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>